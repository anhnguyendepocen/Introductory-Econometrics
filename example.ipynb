{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from main import load_data,get_data,regress,regress_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In example 8.4,we discuss the heteroscedastic problem.\n",
    "\n",
    "Book give a estimated equation.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "\\begin{array}{lllll}\n",
    "\\widehat{price}= & -21.77+ & 0.00207lotsize+ & 0.123sqrft+ & 13.85bdrms \\\\\n",
    "            & (29.48) & (0.00064)     & (0.013)   & (9.01) \\\\\n",
    "\\end{array}\\\\\n",
    "n=88,R^2=0.672\n",
    "\\end{array}\\tag{8.17}\n",
    "$$\n",
    "\n",
    "(I write the formula in a long time.MathJax is confused with surplus \\n input.)\n",
    "\n",
    "We can use a basic command to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.672\n",
      "Model:                            OLS   Adj. R-squared:                  0.661\n",
      "Method:                 Least Squares   F-statistic:                     57.46\n",
      "Date:                Sat, 30 Jan 2016   Prob (F-statistic):           2.70e-20\n",
      "Time:                        15:41:45   Log-Likelihood:                -482.88\n",
      "No. Observations:                  88   AIC:                             973.8\n",
      "Df Residuals:                      84   BIC:                             983.7\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    -21.7703     29.475     -0.739      0.462       -80.385    36.844\n",
      "lotsize        0.0021      0.001      3.220      0.002         0.001     0.003\n",
      "sqrft          0.1228      0.013      9.275      0.000         0.096     0.149\n",
      "bdrms         13.8525      9.010      1.537      0.128        -4.065    31.770\n",
      "==============================================================================\n",
      "Omnibus:                       20.398   Durbin-Watson:                   2.110\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               32.278\n",
      "Skew:                           0.961   Prob(JB):                     9.79e-08\n",
      "Kurtosis:                       5.261   Cond. No.                     6.41e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 6.41e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "r=regress('price~lotsize+sqrft+bdrms','hprice1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks great.But its flexibility is lack. For $R^2_{\\hat{u}^2}$ (what fuck the MathJax display ) , we need return low level to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>resid</td>      <th>  R-squared:         </th> <td>   0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5.339</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 30 Jan 2016</td> <th>  Prob (F-statistic):</th>  <td>0.00205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:41:45</td>     <th>  Log-Likelihood:    </th> <td> -896.99</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    88</td>      <th>  AIC:               </th> <td>   1802.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    84</td>      <th>  BIC:               </th> <td>   1812.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>-5522.7948</td> <td> 3259.478</td> <td>   -1.694</td> <td> 0.094</td> <td> -1.2e+04   959.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lotsize</th> <td>    0.2015</td> <td>    0.071</td> <td>    2.838</td> <td> 0.006</td> <td>    0.060     0.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sqrft</th>   <td>    1.6910</td> <td>    1.464</td> <td>    1.155</td> <td> 0.251</td> <td>   -1.220     4.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bdrms</th>   <td> 1041.7602</td> <td>  996.381</td> <td>    1.046</td> <td> 0.299</td> <td> -939.653  3023.173</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>115.167</td> <th>  Durbin-Watson:     </th> <td>   2.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2267.859</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 4.381</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>26.276</td>  <th>  Cond. No.          </th> <td>6.41e+04</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  resid   R-squared:                       0.160\n",
       "Model:                            OLS   Adj. R-squared:                  0.130\n",
       "Method:                 Least Squares   F-statistic:                     5.339\n",
       "Date:                Sat, 30 Jan 2016   Prob (F-statistic):            0.00205\n",
       "Time:                        15:41:45   Log-Likelihood:                -896.99\n",
       "No. Observations:                  88   AIC:                             1802.\n",
       "Df Residuals:                      84   BIC:                             1812.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "const      -5522.7948   3259.478     -1.694      0.094      -1.2e+04   959.035\n",
       "lotsize        0.2015      0.071      2.838      0.006         0.060     0.343\n",
       "sqrft          1.6910      1.464      1.155      0.251        -1.220     4.602\n",
       "bdrms       1041.7602    996.381      1.046      0.299      -939.653  3023.173\n",
       "==============================================================================\n",
       "Omnibus:                      115.167   Durbin-Watson:                   2.351\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2267.859\n",
       "Skew:                           4.381   Prob(JB):                         0.00\n",
       "Kurtosis:                      26.276   Cond. No.                     6.41e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 6.41e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "y_head='price'\n",
    "X_head=['lotsize','sqrft','bdrms']\n",
    "gd=get_data(y_head,X_head,'hprice1')\n",
    "gd['resid']=r.resid\n",
    "mod=sm.OLS(gd['resid']**2,sm.add_constant(gd[X_head]))\n",
    "res=mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So $R^2_{\\hat{u}^2}=0.160$ (note you should call sm.add_constant, if not you will get constant-free model and a high $R^2$) .It is correspond with book output.\n",
    "\n",
    "Then,we can go the $F$ test path or $\\chi^2$ test path.\n",
    "\n",
    "## Breusch-Pagan test for heteroskedasticity,BP test\n",
    "\n",
    "if $H_0$ is true,then:\n",
    "\n",
    "let $R^2_u=R^2_{\\hat{u}^2}$ avoid the ugly symbol\n",
    "\n",
    "LM statistic\n",
    "\n",
    "$$ LM=nR^2_u \\sim \\chi^2_{k} $$\n",
    "\n",
    "F statistic\n",
    "\n",
    "$$ F=\\frac{R^2_u/k}{(1-R^2_u)/(n-k-1)} \\sim F_{k,n-k-1} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LM p-value:  0.00278205954233\n",
      "F p-value:  0.00204774440967\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "k=res.model.df_model #3\n",
    "n=res.model.nobs #88\n",
    "R2=res.rsquared\n",
    "\n",
    "#chi^2 test\n",
    "LM=n*R2\n",
    "print 'LM p-value: ',1-stats.chi2(k).cdf(LM)\n",
    "\n",
    "#F test\n",
    "F=(R2/k)/((1-R2)/(n-k-1))\n",
    "print 'F p-value: ',1-stats.f(k,n-k-1).cdf(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However,It's impossible a statistic model package don't contain this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14.092385514591086, 0.0027820595423349564, 5.338919367860953, 0.0020477444096706544)\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.diagnostic import het_breushpagan\n",
    "\n",
    "print het_breushpagan(gd['resid'],sm.add_constant(gd[X_head])) # you don't need transform it to **2\n",
    "#print het_breushpagan.__doc__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They're explained by document string below.\n",
    "\n",
    "    lm : float\n",
    "        lagrange multiplier statistic\n",
    "    lm_pvalue :float\n",
    "        p-value of lagrange multiplier test\n",
    "    fvalue : float\n",
    "        f-statistic of the hypothesis that the error variance does not depend\n",
    "        on x\n",
    "    f_pvalue : float\n",
    "        p-value for the f-statistic\n",
    "        \n",
    "The result is validated at all.There's a log trasform example too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LM p-value:  0.238344821018\n",
      "F p-value:  0.245145655823\n"
     ]
    }
   ],
   "source": [
    "r2=regress('np.log(price)~np.log(lotsize)+np.log(sqrft)+bdrms','hprice1',summary=False)\n",
    "LM,LM_p,F,F_p=het_breushpagan(r2.resid,r2.model.exog)\n",
    "print 'LM p-value: ',LM_p\n",
    "print 'F p-value: ',F_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 8.4 All done. Empirical study is easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
